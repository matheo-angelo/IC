{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Model Example\n",
        "\n",
        "In this initial experiment, we will attempt to predict the diagnosis of ASD from fMRI data using Graph Neural Networks. Each sample in the dataset corresponds to an fMRI exam, and from that exam, we construct a graph using a brain atlas reference, which will be the input for the GNN."
      ],
      "metadata": {
        "id": "SBvyEKH4lE3Y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Constructing the full set of graphs\n",
        "\n",
        "An input graph to a GNN consists on a triple $G = (V, E, X)$, where $V$ is the set of notes, $E$ is the set of edges and $X$ is the feature matrix such that the $i$-th row of $X$ contains the feature vector of node $i$.\n",
        "\n",
        "For the set $V$, the nodes of the graph will correspond to Regions Of Interest (ROI), where a region of interest is considered to have an important and specialized function in the brain connectivity. These regions can be categorized using a brain atlas, and here, we will use the AAL atlas, with 116 ROIs.\n",
        "\n",
        "The set of edges $E$ is calculated using the functional connectivity of the brain. In an fMRI exam, each part of the brain has a BOLD signal, a time series that measures brain activity through the presence of blood. Edges in the graph are inserted for pairs of nodes that have high positive correlation in their correspondent BOLD signals.\n",
        "\n",
        "Finally, inspired by the work of [Zhu et al.](https://link.springer.com/chapter/10.1007/978-3-030-93049-3_30), $X$ will be equal to the correlation matrix of the BOLD signals for all regions of interest. Therefore, the feature vector $i$ corresponds to it's partial correlations to every other region of interest in the brain.\n",
        "\n"
      ],
      "metadata": {
        "id": "xX2PM0j2hPMp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import libraries"
      ],
      "metadata": {
        "id": "feVnNzSVHaDC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import networkx as nx\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch"
      ],
      "metadata": {
        "id": "clTIZW8fHZe4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch_version = str(torch.__version__)\n",
        "scatter_src = f\"https://pytorch-geometric.com/whl/torch-{torch_version}.html\"\n",
        "sparse_src = f\"https://pytorch-geometric.com/whl/torch-{torch_version}.html\"\n",
        "!pip install torch-scatter -f $scatter_src\n",
        "!pip install torch-sparse -f $sparse_src\n",
        "!pip install torch-geometric"
      ],
      "metadata": {
        "id": "pXKys8LWVRXl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1131ea9b-85c4-488e-8045-840568777786"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in links: https://pytorch-geometric.com/whl/torch-2.5.1+cu121.html\n",
            "Collecting torch-scatter\n",
            "  Downloading https://data.pyg.org/whl/torch-2.5.0%2Bcu121/torch_scatter-2.1.2%2Bpt25cu121-cp310-cp310-linux_x86_64.whl (10.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.9/10.9 MB\u001b[0m \u001b[31m33.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: torch-scatter\n",
            "Successfully installed torch-scatter-2.1.2+pt25cu121\n",
            "Looking in links: https://pytorch-geometric.com/whl/torch-2.5.1+cu121.html\n",
            "Collecting torch-sparse\n",
            "  Downloading https://data.pyg.org/whl/torch-2.5.0%2Bcu121/torch_sparse-0.6.18%2Bpt25cu121-cp310-cp310-linux_x86_64.whl (5.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.1/5.1 MB\u001b[0m \u001b[31m51.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch-sparse) (1.13.1)\n",
            "Requirement already satisfied: numpy<2.3,>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from scipy->torch-sparse) (1.26.4)\n",
            "Installing collected packages: torch-sparse\n",
            "Successfully installed torch-sparse-0.6.18+pt25cu121\n",
            "Collecting torch-geometric\n",
            "  Downloading torch_geometric-2.6.1-py3-none-any.whl.metadata (63 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.1/63.1 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.11.10)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (2024.10.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.1.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.26.4)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (5.9.5)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.2.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (4.67.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (1.3.2)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (4.0.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (24.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (1.18.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch-geometric) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (2024.12.14)\n",
            "Requirement already satisfied: typing-extensions>=4.1.0 in /usr/local/lib/python3.10/dist-packages (from multidict<7.0,>=4.5->aiohttp->torch-geometric) (4.12.2)\n",
            "Downloading torch_geometric-2.6.1-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m31.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: torch-geometric\n",
            "Successfully installed torch-geometric-2.6.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.set_default_tensor_type(torch.cuda.FloatTensor)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "t_6BLpdRWa4d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f72a404c-2370-4de4-f532-733a03a09c0b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/__init__.py:1144: UserWarning: torch.set_default_tensor_type() is deprecated as of PyTorch 2.1, please use torch.set_default_dtype() and torch.set_default_device() as alternatives. (Triggered internally at ../torch/csrc/tensor/python_tensor.cpp:432.)\n",
            "  _C._set_default_tensor_type(t)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def torch_pearson_correlation_matrix(X):\n",
        "\n",
        "  mean = torch.mean(X, dim=0)\n",
        "  covariance = torch.matmul((X - mean).t(), (X - mean))\n",
        "  variance = torch.diagonal(covariance)\n",
        "  correlation = (variance**(-1/2)) * covariance * ((variance**(-1/2)).t())\n",
        "  return correlation\n",
        "\n",
        "def construct_graph(roi_time_series, threshold=0.7, return_functional_connectivity=True, adjacency_matrix_type='torch', adjacency_representation = 'edge_list'):\n",
        "\n",
        "  roi_time_series = torch.from_numpy(roi_time_series).to(device)\n",
        "  functional_connectivity = torch_pearson_correlation_matrix(roi_time_series)\n",
        "  adjacency = (functional_connectivity > threshold).int().to(device) - torch.eye(len(functional_connectivity))\n",
        "\n",
        "  if adjacency_representation == 'edge_list':\n",
        "    adjacency = (adjacency.nonzero()).t()\n",
        "\n",
        "  if adjacency_matrix_type == 'numpy':\n",
        "    adjacency = adjacency.cpu().numpy()\n",
        "\n",
        "  if return_functional_connectivity==True:\n",
        "    return adjacency, functional_connectivity\n",
        "  else:\n",
        "    return adjacency"
      ],
      "metadata": {
        "id": "rG77rr13KfD9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Obtaining data from the ABIDE I [Preprocessed Connectomes Project](http://preprocessed-connectomes-project.org/abide/download.html), where all fMRI exams have been pre-processed with different brain atlases. As mentioned before, we will use the AAL atlas."
      ],
      "metadata": {
        "id": "9uh1u4XvHWbR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import subprocess\n",
        "from torch_geometric.data import Data\n",
        "\n",
        "def download_sample(sample_name):\n",
        "  destination_folder = '/content/data/fmri'\n",
        "  url = 'https://s3.amazonaws.com/fcp-indi/data/Projects/ABIDE_Initiative/Outputs/cpac/filt_global/rois_aal/{}_rois_aal.1D'.format(sample_name)\n",
        "  subprocess.run([\n",
        "    \"wget\",\n",
        "    \"-P\", destination_folder,\n",
        "    \"--continue\",\n",
        "    \"--quiet\",\n",
        "    \"--no-check-certificate\",\n",
        "    url\n",
        "  ])\n",
        "\n",
        "def get_dataset(threshold=0.7, download=True):\n",
        "\n",
        "  if download==True:\n",
        "    os.makedirs('/content/data/fmri', exist_ok=True)\n",
        "    !wget -P /content/data https://raw.githubusercontent.com/preprocessed-connectomes-project/abide/master/Phenotypic_V1_0b_preprocessed1.csv\n",
        "    phenotypic_data = pd.read_csv('/content/data/Phenotypic_V1_0b_preprocessed1.csv')\n",
        "    phenotypic_data['FILE_ID'].apply(download_sample)\n",
        "\n",
        "  phenotypic_data = pd.read_csv('/content/data/Phenotypic_V1_0b_preprocessed1.csv') #Apagar\n",
        "\n",
        "  data_list = []\n",
        "  for index, row in phenotypic_data.iterrows():\n",
        "    filepath = \"/content/data/fmri/\" + row['FILE_ID'] + \"_rois_aal.1D\"\n",
        "    if not os.path.exists(filepath): #Not every line of the phenotypic table is in the PCP dataset\n",
        "      continue\n",
        "    roi_time_series = np.loadtxt(filepath)\n",
        "    edge_index, x = construct_graph(roi_time_series=roi_time_series, threshold=threshold)\n",
        "    y = torch.tensor([row['DX_GROUP']-1]) #For the graph labels, 0 is for autistic patients and 1 is for typical control (adjusted to 0-1 interval to allow BCE Loss)\n",
        "    data_list.append(Data(x=x, edge_index=edge_index, y=y))\n",
        "\n",
        "  return data_list"
      ],
      "metadata": {
        "id": "MF0Ml-Ka5mZZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = get_dataset()"
      ],
      "metadata": {
        "id": "IiV3keVJltsJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import random_split\n",
        "from torch import Generator\n",
        "\n",
        "train_size = int(0.8 * len(dataset)) #80% of the dataset goes into the training set\n",
        "test_size = len(dataset) - train_size\n",
        "\n",
        "generator = Generator(device='cuda')\n",
        "train_dataset, test_dataset = random_split(dataset, [train_size, test_size], generator=generator)"
      ],
      "metadata": {
        "id": "Z4F7Oe6qRr5k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training the GNN\n",
        "\n",
        "Here, we will use the Graph Attention Network architecture proposed by [Veličković et al.](https://arxiv.org/abs/1710.10903)"
      ],
      "metadata": {
        "id": "fFZJUBI7TPvT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.nn import ModuleList, Sigmoid\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn.conv import GATConv\n",
        "from torch_geometric.nn.pool import global_mean_pool\n",
        "\n",
        "class GAT(torch.nn.Module):\n",
        "  def __init__(self, input_dim, hidden_dim=15, n_heads=4, num_layers=3, dropout=0.5):\n",
        "\n",
        "    super(GAT, self).__init__()\n",
        "    self.dropout = dropout\n",
        "\n",
        "    self.convs = ModuleList()\n",
        "    self.convs.append(GATConv(input_dim, hidden_dim, n_heads))\n",
        "    for l in range(num_layers - 1):\n",
        "      self.convs.append(GATConv(hidden_dim * n_heads, hidden_dim, n_heads))\n",
        "\n",
        "    self.dropout = dropout\n",
        "    self.post_message_passing = nn.Linear(hidden_dim * n_heads, 1)\n",
        "    self.sigmoid = Sigmoid()\n",
        "\n",
        "  def forward(self, data):\n",
        "\n",
        "    x, edge_index, batch = data.x, data.edge_index, data.batch\n",
        "\n",
        "    for i in range(self.num_layers):\n",
        "      x = self.convs[i](x, edge_index)\n",
        "      x = F.relu(x)\n",
        "      x = F.dropout(x, p=self.dropout,training=self.training)\n",
        "\n",
        "    x = global_mean_pool(x, batch)\n",
        "    x = self.post_message_passing(x)\n",
        "    out = self.sigmoid(x)\n",
        "    return out"
      ],
      "metadata": {
        "id": "iKKkapSZjrR1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.nn.functional import binary_cross_entropy as BCELoss\n",
        "from torch.optim import Adam\n",
        "\n",
        "def train(train_loader, n_epochs=1000, learning_rate = 0.01, return_losses = False):\n",
        "\n",
        "  model = GAT(input_dim=116)\n",
        "  optimizer = Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "  losses = []\n",
        "\n",
        "  model.train()\n",
        "  for epoch in range(n_epochs):\n",
        "\n",
        "    total_loss = 0\n",
        "    for batch in train_loader:\n",
        "      optimizer.zero_grad()\n",
        "      prediction = model(batch)\n",
        "      true_label = batch.y\n",
        "      loss = BCELoss(prediction, true_label)\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "      total_loss += loss.item() * batch.num_graphs\n",
        "\n",
        "    losses.append(total_loss)\n",
        "\n",
        "  if return_losses:\n",
        "    return model, losses\n",
        "  return model"
      ],
      "metadata": {
        "id": "cKH8-1LpjdOO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metric import classification_report\n",
        "\n",
        "def test(model, test_loader, losses):\n",
        "\n",
        "  model.eval()\n",
        "\n",
        "  test_prediction = []\n",
        "  test_true_label = []\n",
        "\n",
        "  for batch in test_loader:\n",
        "\n",
        "    output = model(batch)\n",
        "    y_batch_pred = torch.round(output)\n",
        "    test_prediction.extend(y_batch_pred.cpu().numpy())\n",
        "    test_true_label.extend(batch.y.cpu().numpy())\n",
        "\n",
        "  print(\"Classification Report:\")\n",
        "  print(classification_report(test_true_label, test_prediction))\n",
        "\n",
        "  plt.title(\"Decay of loss during training\")\n",
        "  plt.plot(losses)\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "Jz0IlfaOj0kh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=10, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=10, shuffle=False)\n",
        "model, losses = train(train_loader, return_losses=True)\n",
        "\n",
        "test(model, test_loader, losses)"
      ],
      "metadata": {
        "id": "7bWFO1GGTPdK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}