{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Model Example\n",
        "\n",
        "In this initial experiment, we will attempt to predict the diagnosis of ASD from fMRI data using Graph Neural Networks. Each sample in the dataset corresponds to an fMRI exam, and from that exam, we construct a graph using a brain atlas reference, which will be the input for the GNN."
      ],
      "metadata": {
        "id": "SBvyEKH4lE3Y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Constructing the full set of graphs\n",
        "\n",
        "An input graph to a GNN consists on a triple $G = (V, E, X)$, where $V$ is the set of notes, $E$ is the set of edges and $X$ is the feature matrix such that the $i$-th row of $X$ contains the feature vector of node $i$.\n",
        "\n",
        "For the set $V$, the nodes of the graph will correspond to Regions Of Interest (ROI), where a region of interest is considered to have an important and specialized function in the brain connectivity. These regions can be categorized using a brain atlas, and here, we will use the AAL atlas, with 116 ROIs.\n",
        "\n",
        "The set of edges $E$ is calculated using the functional connectivity of the brain. In an fMRI exam, each part of the brain has a BOLD signal, a time series that measures brain activity through the presence of blood. Edges in the graph are inserted for pairs of nodes that have high positive correlation in their correspondent BOLD signals.\n",
        "\n",
        "Finally, inspired by the work of [Zhu et al.](https://link.springer.com/chapter/10.1007/978-3-030-93049-3_30), $X$ will be equal to the correlation matrix of the BOLD signals for all regions of interest. Therefore, the feature vector $i$ corresponds to it's partial correlations to every other region of interest in the brain.\n",
        "\n"
      ],
      "metadata": {
        "id": "xX2PM0j2hPMp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import libraries"
      ],
      "metadata": {
        "id": "feVnNzSVHaDC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import networkx as nx\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch"
      ],
      "metadata": {
        "id": "clTIZW8fHZe4"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch_version = str(torch.__version__)\n",
        "scatter_src = f\"https://pytorch-geometric.com/whl/torch-{torch_version}.html\"\n",
        "sparse_src = f\"https://pytorch-geometric.com/whl/torch-{torch_version}.html\"\n",
        "!pip install torch-scatter -f $scatter_src\n",
        "!pip install torch-sparse -f $sparse_src\n",
        "!pip install torch-geometric"
      ],
      "metadata": {
        "id": "pXKys8LWVRXl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "837a69ce-2db6-435a-c0dd-9b98c84a7dd5"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in links: https://pytorch-geometric.com/whl/torch-2.5.1+cu124.html\n",
            "Requirement already satisfied: torch-scatter in /usr/local/lib/python3.11/dist-packages (2.1.2+pt25cu124)\n",
            "Looking in links: https://pytorch-geometric.com/whl/torch-2.5.1+cu124.html\n",
            "Requirement already satisfied: torch-sparse in /usr/local/lib/python3.11/dist-packages (0.6.18+pt25cu124)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from torch-sparse) (1.13.1)\n",
            "Requirement already satisfied: numpy<2.3,>=1.22.4 in /usr/local/lib/python3.11/dist-packages (from scipy->torch-sparse) (1.26.4)\n",
            "Requirement already satisfied: torch-geometric in /usr/local/lib/python3.11/dist-packages (2.6.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (3.11.11)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (2024.10.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (3.1.5)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (1.26.4)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (5.9.5)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (3.2.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (4.67.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (1.18.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch-geometric) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric) (2024.12.14)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "t_6BLpdRWa4d"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def torch_pearson_correlation_matrix(X):\n",
        "\n",
        "  mean = torch.mean(X, dim=0)\n",
        "  covariance = torch.matmul((X - mean).t(), (X - mean))\n",
        "  variance = torch.diagonal(covariance)\n",
        "  correlation = (variance**(-1/2)) * covariance * ((variance**(-1/2)).t())\n",
        "  return correlation\n",
        "\n",
        "def construct_graph(roi_time_series, threshold=0.7, return_functional_connectivity=True, adjacency_matrix_type='torch', adjacency_representation = 'edge_list'):\n",
        "\n",
        "  roi_time_series = torch.from_numpy(roi_time_series).to(device)\n",
        "  functional_connectivity = torch_pearson_correlation_matrix(roi_time_series)\n",
        "  adjacency = (functional_connectivity > threshold).int().to(device) - torch.eye(len(functional_connectivity)).to(device)\n",
        "\n",
        "  if adjacency_representation == 'edge_list':\n",
        "    adjacency = (adjacency.nonzero()).t()\n",
        "\n",
        "  if adjacency_matrix_type == 'numpy':\n",
        "    adjacency = adjacency.cpu().numpy()\n",
        "\n",
        "  if return_functional_connectivity==True:\n",
        "    return adjacency, functional_connectivity\n",
        "  else:\n",
        "    return adjacency"
      ],
      "metadata": {
        "id": "rG77rr13KfD9"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Obtaining data from the ABIDE I [Preprocessed Connectomes Project](http://preprocessed-connectomes-project.org/abide/download.html), where all fMRI exams have been pre-processed with different brain atlases. As mentioned before, we will use the AAL atlas."
      ],
      "metadata": {
        "id": "9uh1u4XvHWbR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import subprocess\n",
        "from torch_geometric.data import Data\n",
        "from tqdm import tqdm\n",
        "\n",
        "def download_sample(sample_name):\n",
        "  destination_folder = '/content/data/fmri'\n",
        "  url = 'https://s3.amazonaws.com/fcp-indi/data/Projects/ABIDE_Initiative/Outputs/cpac/filt_global/rois_aal/{}_rois_aal.1D'.format(sample_name)\n",
        "  subprocess.run([\n",
        "    \"wget\",\n",
        "    \"-P\", destination_folder,\n",
        "    \"--continue\",\n",
        "    \"--quiet\",\n",
        "    \"--no-check-certificate\",\n",
        "    url\n",
        "  ])\n",
        "\n",
        "def get_dataset(threshold=0.7, download=True):\n",
        "\n",
        "  if download==True:\n",
        "    os.makedirs('/content/data/fmri', exist_ok=True)\n",
        "    !wget -P /content/data https://raw.githubusercontent.com/preprocessed-connectomes-project/abide/master/Phenotypic_V1_0b_preprocessed1.csv\n",
        "    phenotypic_data = pd.read_csv('/content/data/Phenotypic_V1_0b_preprocessed1.csv')\n",
        "    phenotypic_data['FILE_ID'].apply(download_sample)\n",
        "\n",
        "  phenotypic_data = pd.read_csv('/content/data/Phenotypic_V1_0b_preprocessed1.csv') #Apagar\n",
        "\n",
        "  data_list = []\n",
        "  for index, row in tqdm(phenotypic_data.iterrows(), desc='Obtaining dataset:'):\n",
        "    filepath = \"/content/data/fmri/\" + row['FILE_ID'] + \"_rois_aal.1D\"\n",
        "    if not os.path.exists(filepath): #Not every line of the phenotypic table is in the PCP dataset\n",
        "      continue\n",
        "    roi_time_series = np.loadtxt(filepath)\n",
        "    edge_index, x = construct_graph(roi_time_series=roi_time_series, threshold=threshold)\n",
        "    y = torch.tensor([row['DX_GROUP']-1]) #For the graph labels, 0 is for autistic patients and 1 is for typical control (adjusted to 0-1 interval to allow BCE Loss)\n",
        "    data_list.append(Data(x=x, edge_index=edge_index, y=y))\n",
        "\n",
        "  return data_list"
      ],
      "metadata": {
        "id": "MF0Ml-Ka5mZZ"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = get_dataset()"
      ],
      "metadata": {
        "id": "IiV3keVJltsJ",
        "outputId": "c6c135cc-b9f0-402e-ddf0-e08b4d082ac8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-02-01 19:51:50--  https://raw.githubusercontent.com/preprocessed-connectomes-project/abide/master/Phenotypic_V1_0b_preprocessed1.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 449443 (439K) [text/plain]\n",
            "Saving to: ‘/content/data/Phenotypic_V1_0b_preprocessed1.csv’\n",
            "\n",
            "Phenotypic_V1_0b_pr 100%[===================>] 438.91K  --.-KB/s    in 0.05s   \n",
            "\n",
            "2025-02-01 19:51:51 (9.35 MB/s) - ‘/content/data/Phenotypic_V1_0b_preprocessed1.csv’ saved [449443/449443]\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Obtaining dataset:: 1112it [00:06, 167.12it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train_dataset, test_dataset = train_test_split(dataset, test_size=0.2)"
      ],
      "metadata": {
        "id": "Z4F7Oe6qRr5k"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training the GNN\n",
        "\n",
        "Here, we will use the Graph Attention Network architecture proposed by [Veličković et al.](https://arxiv.org/abs/1710.10903)"
      ],
      "metadata": {
        "id": "fFZJUBI7TPvT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.nn import ModuleList, Sigmoid\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn.conv import GATConv\n",
        "from torch_geometric.nn.pool import global_mean_pool\n",
        "\n",
        "class GAT(torch.nn.Module):\n",
        "  def __init__(self, input_dim, hidden_dim=15, n_heads=4, num_layers=3, dropout=0.8):\n",
        "\n",
        "    super(GAT, self).__init__()\n",
        "    self.dropout = dropout\n",
        "    self.num_layers = num_layers\n",
        "\n",
        "    self.convs = ModuleList()\n",
        "    self.convs.append(GATConv(input_dim, hidden_dim, n_heads))\n",
        "    for l in range(num_layers - 1):\n",
        "      self.convs.append(GATConv(hidden_dim * n_heads, hidden_dim, n_heads))\n",
        "\n",
        "    self.dropout = dropout\n",
        "    self.post_message_passing = nn.Linear(hidden_dim * n_heads, 1)\n",
        "    self.sigmoid = Sigmoid()\n",
        "\n",
        "  def forward(self, data):\n",
        "\n",
        "    x, edge_index, batch = data.x, data.edge_index, data.batch\n",
        "\n",
        "    for i in range(self.num_layers):\n",
        "      x = self.convs[i](x, edge_index)\n",
        "      x = F.leaky_relu(x)\n",
        "      x = F.dropout(x, p=self.dropout,training=self.training)\n",
        "\n",
        "    x = global_mean_pool(x, batch)\n",
        "    x = self.post_message_passing(x).squeeze(1)\n",
        "    out = self.sigmoid(x)\n",
        "    return out"
      ],
      "metadata": {
        "id": "iKKkapSZjrR1"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.nn.functional import binary_cross_entropy as BCELoss\n",
        "from torch.optim import Adam\n",
        "\n",
        "def train(train_loader, n_epochs=1000, learning_rate = 0.01, return_losses = False):\n",
        "\n",
        "  model = GAT(input_dim=116)\n",
        "  model = model.to(device)\n",
        "  optimizer = Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "  losses = []\n",
        "\n",
        "  model.train()\n",
        "\n",
        "  for epoch in range(n_epochs):\n",
        "\n",
        "    total_loss = 0\n",
        "    for batch in train_loader:\n",
        "\n",
        "      batch.x, batch.y = batch.x.float(), batch.y.float()\n",
        "      optimizer.zero_grad()\n",
        "      prediction = model(batch)\n",
        "      true_label = (batch.y).to(device)\n",
        "      print(\"prediction: {}, true label: {}\".format(prediction, true_label))\n",
        "      loss = BCELoss(prediction, true_label)\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "      total_loss += loss.item() * batch.num_graphs\n",
        "\n",
        "    losses.append(total_loss)\n",
        "\n",
        "  if return_losses:\n",
        "    return model, losses\n",
        "  return model"
      ],
      "metadata": {
        "id": "cKH8-1LpjdOO"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "def test(model, test_loader, losses):\n",
        "\n",
        "  model.eval()\n",
        "\n",
        "  test_prediction = []\n",
        "  test_true_label = []\n",
        "\n",
        "  for batch in test_loader:\n",
        "\n",
        "    output = model(batch)\n",
        "    y_batch_pred = torch.round(output)\n",
        "    test_prediction.extend(y_batch_pred.cpu().numpy())\n",
        "    test_true_label.extend(batch.y.cpu().numpy())\n",
        "\n",
        "  print(\"Classification Report:\")\n",
        "  print(classification_report(test_true_label, test_prediction))\n",
        "\n",
        "  plt.title(\"Decay of loss during training\")\n",
        "  plt.plot(losses)\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "Jz0IlfaOj0kh"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch_geometric.loader import DataLoader\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=1, shuffle=False)\n",
        "test_loader = DataLoader(test_dataset, batch_size=10, shuffle=False)\n",
        "model, losses = train(train_loader, return_losses=True)\n",
        "\n",
        "test(model, test_loader, losses)"
      ],
      "metadata": {
        "id": "7bWFO1GGTPdK",
        "outputId": "e8fc3e1a-d924-448c-cb51-8bda3ccb7175",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 633
        }
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "prediction: tensor([0.5640], grad_fn=<SigmoidBackward0>), true label: tensor([0.])\n",
            "prediction: tensor([0.4027], grad_fn=<SigmoidBackward0>), true label: tensor([0.])\n",
            "prediction: tensor([0.2078], grad_fn=<SigmoidBackward0>), true label: tensor([0.])\n",
            "prediction: tensor([3.2070e-06], grad_fn=<SigmoidBackward0>), true label: tensor([0.])\n",
            "prediction: tensor([4.0019e-30], grad_fn=<SigmoidBackward0>), true label: tensor([1.])\n",
            "prediction: tensor([0.0100], grad_fn=<SigmoidBackward0>), true label: tensor([0.])\n",
            "prediction: tensor([0.0025], grad_fn=<SigmoidBackward0>), true label: tensor([0.])\n",
            "prediction: tensor([0.0138], grad_fn=<SigmoidBackward0>), true label: tensor([0.])\n",
            "prediction: tensor([1.1553e-05], grad_fn=<SigmoidBackward0>), true label: tensor([1.])\n",
            "prediction: tensor([0.0011], grad_fn=<SigmoidBackward0>), true label: tensor([0.])\n",
            "prediction: tensor([1.0105e-05], grad_fn=<SigmoidBackward0>), true label: tensor([1.])\n",
            "prediction: tensor([0.0005], grad_fn=<SigmoidBackward0>), true label: tensor([1.])\n",
            "prediction: tensor([0.0099], grad_fn=<SigmoidBackward0>), true label: tensor([1.])\n",
            "prediction: tensor([0.0297], grad_fn=<SigmoidBackward0>), true label: tensor([1.])\n",
            "prediction: tensor([nan], grad_fn=<SigmoidBackward0>), true label: tensor([1.])\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "all elements of input should be between 0 and 1",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-76-f03a5ee347ae>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtrain_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtest_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlosses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_losses\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlosses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-74-02935db1a5ad>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(train_loader, n_epochs, learning_rate, return_losses)\u001b[0m\n\u001b[1;32m     22\u001b[0m       \u001b[0mtrue_label\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m       \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"prediction: {}, true label: {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprediction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrue_label\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m       \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBCELoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprediction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrue_label\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m       \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m       \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mbinary_cross_entropy\u001b[0;34m(input, target, weight, size_average, reduce, reduction)\u001b[0m\n\u001b[1;32m   3552\u001b[0m         \u001b[0mweight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3553\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3554\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary_cross_entropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction_enum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3555\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3556\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: all elements of input should be between 0 and 1"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ttOmU7JDixJW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}